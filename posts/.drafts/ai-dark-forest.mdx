---
title: "The Expanding Dark Forest and Generative AI"
description: "How generative AI tools will flood the web with noise and humans will learn to adapt with weird signalling"
updated: "2022-12-10"
startDate: "2022-12-09"
type: "note"
topics: ["Anthropology", "The Web"]
growthStage: "seedling"
---

<AssumedAudience>
  People who have heard of GPT-3 and are vaguely following the advances in
  machine learning, large language models, and image generators.
</AssumedAudience>

<Spacer size="xs" />

<IntroParagraph>

The [[dark forest theory]] of the web points to the increasingly like-like but life-less state of being online.<Footnote idName={1}>[Dark Forest](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) [Theory of](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) [the Internet](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) by Yancey Strickler</Footnote> Most open and publicly available spaces on the web are overrun with bots, advertisers, trolls, data scrapers, clickbait, keyword-stuffing “content creators,” and algorithmically manipulated junk.

</IntroParagraph>

It's like a dark forest that seems eerily quiet – all the living creatures are hidden beneath the ground or up in trees. If they reveal themselves, they risk being attacked by automated predators. Humans who want to engage in informal, unoptimised, personal interactions have to hide in closed spaces like invite-only Slack channels, Discord groups, and email newsletters. Or make themselves [illegible](https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/) and algorithmically incoherent in public venues.

That dark forest is about to <div style={{transform: "scaleX(1.85)", display: "inline-flex", margin: "0 2.2rem"}}>expand</div>. Large Language Models (LLMs) that can instantly generate coherent swaths of human-like text have just joined the party.

Over the last six months, we've seen a flood of LLM copywriting and content-generation products come out: [Jasper](https://www.jasper.ai/), [Moonbeam](https://www.gomoonbeam.com/), [Copy.ai](https://www.copy.ai/), and [Anyword](https://anyword.com/) are just a few. They're designed to pump out advertising copy, blog posts, emails, social media updates, and marketing pages. And they're _really_ good at it.<Footnote idName={2}>Primarily because [GPT-3](https://en.wikipedia.org/wiki/GPT-3) which powers many of these products was specifically trained on text from the web. It's intimately familiar with the style of language we use online.</Footnote>

The come to Jesus moment for many people happened last week when OpenAI released [ChatGPT](https://openai.com/blog/chatgpt/), a significantly more capable version of GPT-3. <Footnote isClosed idName={3}>They're calling it GPT-3.5. It's the same model with human [reinforcement learning](https://huggingface.co/blog/rlhf) layered on top.</Footnote> And it's early days yet.

Not far behind them are image generators like [Midjourney](), [DALL-E](), and [Stable Diffusion]()

## A Generated Web

Get ready for a web where LLMs link up with social media schedulers to publish a relentless and impossibly banal stream of LinkedIn updates, “engaging” tweets, Facebook tirades, and corporate blog posts.

You thought the first page of Google was bunk before? You haven't seen Google where SEO optimizer bros pump out billions of perfectly coherent, predictable, and generic informational articles for every longtail keyword combination under the sun. Goodbye to finding original human insights under that pile of cruft.

Simply put, we are about to be flooded by noise.

A large chunk of the web is about to become a pure bot interchange. They'll write, read, and respond to one another. Mimicking the human attention and interaction that earns advertising $$$. One giant echo chamber of automated interactions.

I buy a lot of Tim Hwang's arguments in [_Subprime Attention Crisis:_]() _Advertising and the Time Bomb at the Heart of the Internet_. Namely that online advertising is a bubble. The market and algorithmic efficiencies of programmatic advertising mean that ad slots are bought and sold every few milliseconds, faster than a human can blink.

Bots create the ads, buy and sell the ads, and mimic a real human clicking and reading the ads. It's a facsimile of human attention exchange.

## Passing the Reverse Turing Test

On a web overrun with automated bots, language models, and image generators, our new challenge as humans will be to prove we aren't language models. It's the reverse [turing test](https://en.wikipedia.org/wiki/Turing_test).

Before you continue, pause and consider: How would you prove you're not a language model generating predictive text?

<TweetEmbed tweetId="1601541418153304064" />

We have to prove we're not language models with more original thought. More analysis of the world offline of things bots could never access.

Forgive the optimism, but I think we're going to get quite good at it.

It's a good opportunity to do what we're best at – cultural adaptation. We've designed a system that automates a standardised way of writing. We have codified _la langue_ – the official language of the culture.

But there is still _la parle_ – the individual and nuanced speech acts of people.

We'll develop neologisms, inside signals, codes, novel dialects. Anything to signal we are not a language model. Not unlike teenagers trying to subvert their elders through in-group jargon.

For now, they can't make original, sweeping conclusions from a broad reading of the literature.

There's a lot of hope in this vision. In a world of automated intelligence, our goalposts for intelligence will shift. We'll raise our quality bar for what we expect from humans. When a machine can pump out a great summary of existing work, there's no value in a person doing it.

incorporate unique turns of phrase or personal anecdotes that are specific to their own experiences and backgrounds. They could also include references to current events or other real-world phenomena that would be difficult for an LLM to accurately model or reproduce

We'll have to become critical thinkers proposing non-probabilistic ideas. fostering a greater sense of critical thinking and skepticism.

We could go down the route of verification and authentication. “Signing” content with (oh god no) the blockchain.
